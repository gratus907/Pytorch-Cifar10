Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
            Conv2d-4           [-1, 16, 32, 32]           2,304
       BatchNorm2d-5           [-1, 16, 32, 32]              32
              ReLU-6           [-1, 16, 32, 32]               0
            Conv2d-7           [-1, 16, 32, 32]           2,304
       BatchNorm2d-8           [-1, 16, 32, 32]              32
              ReLU-9           [-1, 16, 32, 32]               0
         ResBlock-10           [-1, 16, 32, 32]               0
           Conv2d-11           [-1, 16, 32, 32]           2,304
      BatchNorm2d-12           [-1, 16, 32, 32]              32
             ReLU-13           [-1, 16, 32, 32]               0
           Conv2d-14           [-1, 16, 32, 32]           2,304
      BatchNorm2d-15           [-1, 16, 32, 32]              32
             ReLU-16           [-1, 16, 32, 32]               0
         ResBlock-17           [-1, 16, 32, 32]               0
           Conv2d-18           [-1, 16, 32, 32]           2,304
      BatchNorm2d-19           [-1, 16, 32, 32]              32
             ReLU-20           [-1, 16, 32, 32]               0
           Conv2d-21           [-1, 16, 32, 32]           2,304
      BatchNorm2d-22           [-1, 16, 32, 32]              32
             ReLU-23           [-1, 16, 32, 32]               0
         ResBlock-24           [-1, 16, 32, 32]               0
           Conv2d-25           [-1, 32, 16, 16]           4,608
      BatchNorm2d-26           [-1, 32, 16, 16]              64
             ReLU-27           [-1, 32, 16, 16]               0
           Conv2d-28           [-1, 32, 16, 16]           9,216
      BatchNorm2d-29           [-1, 32, 16, 16]              64
           Conv2d-30           [-1, 32, 16, 16]           4,608
      BatchNorm2d-31           [-1, 32, 16, 16]              64
             ReLU-32           [-1, 32, 16, 16]               0
         ResBlock-33           [-1, 32, 16, 16]               0
           Conv2d-34           [-1, 32, 16, 16]           9,216
      BatchNorm2d-35           [-1, 32, 16, 16]              64
             ReLU-36           [-1, 32, 16, 16]               0
           Conv2d-37           [-1, 32, 16, 16]           9,216
      BatchNorm2d-38           [-1, 32, 16, 16]              64
             ReLU-39           [-1, 32, 16, 16]               0
         ResBlock-40           [-1, 32, 16, 16]               0
           Conv2d-41           [-1, 32, 16, 16]           9,216
      BatchNorm2d-42           [-1, 32, 16, 16]              64
             ReLU-43           [-1, 32, 16, 16]               0
           Conv2d-44           [-1, 32, 16, 16]           9,216
      BatchNorm2d-45           [-1, 32, 16, 16]              64
             ReLU-46           [-1, 32, 16, 16]               0
         ResBlock-47           [-1, 32, 16, 16]               0
           Conv2d-48             [-1, 64, 8, 8]          18,432
      BatchNorm2d-49             [-1, 64, 8, 8]             128
             ReLU-50             [-1, 64, 8, 8]               0
           Conv2d-51             [-1, 64, 8, 8]          36,864
      BatchNorm2d-52             [-1, 64, 8, 8]             128
           Conv2d-53             [-1, 64, 8, 8]          18,432
      BatchNorm2d-54             [-1, 64, 8, 8]             128
             ReLU-55             [-1, 64, 8, 8]               0
         ResBlock-56             [-1, 64, 8, 8]               0
           Conv2d-57             [-1, 64, 8, 8]          36,864
      BatchNorm2d-58             [-1, 64, 8, 8]             128
             ReLU-59             [-1, 64, 8, 8]               0
           Conv2d-60             [-1, 64, 8, 8]          36,864
      BatchNorm2d-61             [-1, 64, 8, 8]             128
             ReLU-62             [-1, 64, 8, 8]               0
         ResBlock-63             [-1, 64, 8, 8]               0
           Conv2d-64             [-1, 64, 8, 8]          36,864
      BatchNorm2d-65             [-1, 64, 8, 8]             128
             ReLU-66             [-1, 64, 8, 8]               0
           Conv2d-67             [-1, 64, 8, 8]          36,864
      BatchNorm2d-68             [-1, 64, 8, 8]             128
             ReLU-69             [-1, 64, 8, 8]               0
         ResBlock-70             [-1, 64, 8, 8]               0
        AvgPool2d-71             [-1, 64, 1, 1]               0
           Linear-72                   [-1, 10]             650
           ResNet-73                   [-1, 10]               0
================================================================
Total params: 292,954
Trainable params: 292,954
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 5.16
Params size (MB): 1.12
Estimated Total Size (MB): 6.29
----------------------------------------------------------------

(tensor(292954), tensor(292954))
DATASET : CIFAR-10
MODEL : resnet20-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2c11af220>
EPOCH 1 training begins...
Train epoch 1 / 50 Loss 2.1355, Accuracy 20.86% Training Time 0.20 min
saved model to ./pretrained/resnet20-cifar-50
Validation epoch 1 / 50 Loss 1.8872, Accuracy 29.34%

EPOCH 2 training begins...
Train epoch 2 / 50 Loss 1.8366, Accuracy 30.52% Training Time 0.20 min
Validation epoch 2 / 50 Loss 1.7146, Accuracy 36.74%

EPOCH 3 training begins...
Train epoch 3 / 50 Loss 1.6657, Accuracy 37.59% Training Time 0.20 min
Validation epoch 3 / 50 Loss 1.5371, Accuracy 42.33%

EPOCH 4 training begins...
Train epoch 4 / 50 Loss 1.5783, Accuracy 41.06% Training Time 0.20 min
Validation epoch 4 / 50 Loss 1.5347, Accuracy 43.88%

EPOCH 5 training begins...
Train epoch 5 / 50 Loss 1.4861, Accuracy 44.80% Training Time 0.20 min
Validation epoch 5 / 50 Loss 1.3952, Accuracy 48.50%

EPOCH 6 training begins...
Train epoch 6 / 50 Loss 1.4423, Accuracy 46.78% Training Time 0.20 min
Validation epoch 6 / 50 Loss 1.3594, Accuracy 49.79%

EPOCH 7 training begins...
Train epoch 7 / 50 Loss 1.3699, Accuracy 50.00% Training Time 0.20 min
Validation epoch 7 / 50 Loss 1.3513, Accuracy 50.93%

EPOCH 8 training begins...
Train epoch 8 / 50 Loss 1.3351, Accuracy 51.23% Training Time 0.20 min
Validation epoch 8 / 50 Loss 1.2963, Accuracy 52.33%

EPOCH 9 training begins...
Train epoch 9 / 50 Loss 1.2791, Accuracy 53.41% Training Time 0.20 min
Validation epoch 9 / 50 Loss 1.2596, Accuracy 55.46%

EPOCH 10 training begins...
Train epoch 10 / 50 Loss 1.2556, Accuracy 54.55% Training Time 0.20 min
Validation epoch 10 / 50 Loss 1.2393, Accuracy 55.14%

EPOCH 11 training begins...
Train epoch 11 / 50 Loss 1.2124, Accuracy 56.13% Training Time 0.20 min
Validation epoch 11 / 50 Loss 1.1668, Accuracy 58.16%

EPOCH 12 training begins...
Train epoch 12 / 50 Loss 1.1582, Accuracy 57.97% Training Time 0.20 min
Validation epoch 12 / 50 Loss 1.1040, Accuracy 60.53%

EPOCH 13 training begins...
Train epoch 13 / 50 Loss 1.1107, Accuracy 60.08% Training Time 0.20 min
Validation epoch 13 / 50 Loss 1.0777, Accuracy 61.40%

EPOCH 14 training begins...
Train epoch 14 / 50 Loss 1.0798, Accuracy 61.10% Training Time 0.20 min
Validation epoch 14 / 50 Loss 1.0950, Accuracy 61.18%

EPOCH 15 training begins...
Train epoch 15 / 50 Loss 1.0557, Accuracy 62.14% Training Time 0.21 min
Validation epoch 15 / 50 Loss 1.0220, Accuracy 63.69%

EPOCH 16 training begins...
Train epoch 16 / 50 Loss 1.0345, Accuracy 62.76% Training Time 0.20 min
Validation epoch 16 / 50 Loss 0.9909, Accuracy 64.47%

EPOCH 17 training begins...
Train epoch 17 / 50 Loss 1.0076, Accuracy 63.96% Training Time 0.20 min
Validation epoch 17 / 50 Loss 0.9641, Accuracy 65.44%

EPOCH 18 training begins...
Train epoch 18 / 50 Loss 1.0152, Accuracy 63.61% Training Time 0.20 min
Validation epoch 18 / 50 Loss 1.0289, Accuracy 64.12%

EPOCH 19 training begins...
Train epoch 19 / 50 Loss 0.9567, Accuracy 65.82% Training Time 0.20 min
Validation epoch 19 / 50 Loss 1.0009, Accuracy 64.60%

EPOCH 20 training begins...
Train epoch 20 / 50 Loss 0.9557, Accuracy 65.70% Training Time 0.20 min
Validation epoch 20 / 50 Loss 0.9172, Accuracy 67.40%

EPOCH 21 training begins...
Train epoch 21 / 50 Loss 0.9129, Accuracy 67.60% Training Time 0.20 min
Validation epoch 21 / 50 Loss 0.9115, Accuracy 68.49%

EPOCH 22 training begins...
Train epoch 22 / 50 Loss 0.9071, Accuracy 67.64% Training Time 0.20 min
Validation epoch 22 / 50 Loss 0.9081, Accuracy 68.03%

EPOCH 23 training begins...
Train epoch 23 / 50 Loss 0.8978, Accuracy 67.88% Training Time 0.20 min
Validation epoch 23 / 50 Loss 0.9237, Accuracy 67.46%

EPOCH 24 training begins...
Train epoch 24 / 50 Loss 0.8937, Accuracy 68.01% Training Time 0.20 min
Validation epoch 24 / 50 Loss 0.8857, Accuracy 69.45%

EPOCH 25 training begins...
Train epoch 25 / 50 Loss 0.8645, Accuracy 69.43% Training Time 0.20 min
Validation epoch 25 / 50 Loss 0.8838, Accuracy 69.36%

EPOCH 26 training begins...
Train epoch 26 / 50 Loss 0.8390, Accuracy 70.08% Training Time 0.20 min
Validation epoch 26 / 50 Loss 0.8629, Accuracy 69.96%

EPOCH 27 training begins...
Train epoch 27 / 50 Loss 0.8288, Accuracy 70.62% Training Time 0.20 min
Validation epoch 27 / 50 Loss 0.8662, Accuracy 69.87%

EPOCH 28 training begins...
Train epoch 28 / 50 Loss 0.8089, Accuracy 71.25% Training Time 0.20 min
Validation epoch 28 / 50 Loss 0.8262, Accuracy 71.29%

EPOCH 29 training begins...
Train epoch 29 / 50 Loss 0.7996, Accuracy 71.47% Training Time 0.20 min
Validation epoch 29 / 50 Loss 0.7988, Accuracy 71.92%

EPOCH 30 training begins...
Train epoch 30 / 50 Loss 0.7873, Accuracy 72.15% Training Time 0.20 min
Validation epoch 30 / 50 Loss 0.8098, Accuracy 72.27%

EPOCH 31 training begins...
Train epoch 31 / 50 Loss 0.7787, Accuracy 72.45% Training Time 0.20 min
Validation epoch 31 / 50 Loss 0.7911, Accuracy 72.52%

EPOCH 32 training begins...
Train epoch 32 / 50 Loss 0.7504, Accuracy 73.36% Training Time 0.20 min
Validation epoch 32 / 50 Loss 0.7731, Accuracy 73.40%

EPOCH 33 training begins...
Train epoch 33 / 50 Loss 0.7458, Accuracy 73.62% Training Time 0.20 min
Validation epoch 33 / 50 Loss 0.7930, Accuracy 72.19%

EPOCH 34 training begins...
Train epoch 34 / 50 Loss 0.7364, Accuracy 73.91% Training Time 0.20 min
Validation epoch 34 / 50 Loss 0.7651, Accuracy 73.83%

EPOCH 35 training begins...
Train epoch 35 / 50 Loss 0.7222, Accuracy 74.76% Training Time 0.20 min
Validation epoch 35 / 50 Loss 0.7206, Accuracy 74.95%

EPOCH 36 training begins...
Train epoch 36 / 50 Loss 0.7104, Accuracy 75.10% Training Time 0.20 min
Validation epoch 36 / 50 Loss 0.7326, Accuracy 75.20%

EPOCH 37 training begins...
Train epoch 37 / 50 Loss 0.6959, Accuracy 75.40% Training Time 0.20 min
Validation epoch 37 / 50 Loss 0.7736, Accuracy 73.58%

EPOCH 38 training begins...
Train epoch 38 / 50 Loss 0.6935, Accuracy 75.50% Training Time 0.20 min
Validation epoch 38 / 50 Loss 0.7827, Accuracy 74.14%

EPOCH 39 training begins...
Train epoch 39 / 50 Loss 0.6804, Accuracy 75.98% Training Time 0.20 min
Validation epoch 39 / 50 Loss 0.7237, Accuracy 75.21%

EPOCH 40 training begins...
Train epoch 40 / 50 Loss 0.6357, Accuracy 77.79% Training Time 0.20 min
Validation epoch 40 / 50 Loss 0.7082, Accuracy 76.37%

EPOCH 41 training begins...
Train epoch 41 / 50 Loss 0.6300, Accuracy 77.74% Training Time 0.20 min
Validation epoch 41 / 50 Loss 0.6898, Accuracy 76.85%

EPOCH 42 training begins...
Train epoch 42 / 50 Loss 0.6226, Accuracy 78.08% Training Time 0.20 min
Validation epoch 42 / 50 Loss 0.6752, Accuracy 77.62%

EPOCH 43 training begins...
Train epoch 43 / 50 Loss 0.6199, Accuracy 78.29% Training Time 0.20 min
Validation epoch 43 / 50 Loss 0.6959, Accuracy 76.52%

EPOCH 44 training begins...
Train epoch 44 / 50 Loss 0.6230, Accuracy 78.20% Training Time 0.20 min
Validation epoch 44 / 50 Loss 0.6542, Accuracy 77.73%

EPOCH 45 training begins...
Train epoch 45 / 50 Loss 0.6141, Accuracy 78.56% Training Time 0.20 min
Validation epoch 45 / 50 Loss 0.6696, Accuracy 77.66%

EPOCH 46 training begins...
Train epoch 46 / 50 Loss 0.6044, Accuracy 78.78% Training Time 0.20 min
Validation epoch 46 / 50 Loss 0.6596, Accuracy 77.95%

EPOCH 47 training begins...
Train epoch 47 / 50 Loss 0.5990, Accuracy 78.79% Training Time 0.20 min
Validation epoch 47 / 50 Loss 0.6547, Accuracy 78.17%

EPOCH 48 training begins...
Train epoch 48 / 50 Loss 0.5977, Accuracy 79.03% Training Time 0.20 min
Validation epoch 48 / 50 Loss 0.6505, Accuracy 78.03%

EPOCH 49 training begins...
Train epoch 49 / 50 Loss 0.5909, Accuracy 79.26% Training Time 0.20 min
Validation epoch 49 / 50 Loss 0.6902, Accuracy 77.44%

EPOCH 50 training begins...
Train epoch 50 / 50 Loss 0.5893, Accuracy 79.24% Training Time 0.20 min
Validation epoch 50 / 50 Loss 0.6627, Accuracy 78.12%

Total training time 11.46 minutes taken
DATASET : CIFAR-10
MODEL : resnet20-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.0005
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2c11af220>
TESTSET AVG LOSS : 0.66
TESTSET AVG ACCR : 78.12%
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
            Conv2d-4           [-1, 16, 32, 32]           2,304
       BatchNorm2d-5           [-1, 16, 32, 32]              32
              ReLU-6           [-1, 16, 32, 32]               0
            Conv2d-7           [-1, 16, 32, 32]           2,304
       BatchNorm2d-8           [-1, 16, 32, 32]              32
              ReLU-9           [-1, 16, 32, 32]               0
         ResBlock-10           [-1, 16, 32, 32]               0
           Conv2d-11           [-1, 16, 32, 32]           2,304
      BatchNorm2d-12           [-1, 16, 32, 32]              32
             ReLU-13           [-1, 16, 32, 32]               0
           Conv2d-14           [-1, 16, 32, 32]           2,304
      BatchNorm2d-15           [-1, 16, 32, 32]              32
             ReLU-16           [-1, 16, 32, 32]               0
         ResBlock-17           [-1, 16, 32, 32]               0
           Conv2d-18           [-1, 16, 32, 32]           2,304
      BatchNorm2d-19           [-1, 16, 32, 32]              32
             ReLU-20           [-1, 16, 32, 32]               0
           Conv2d-21           [-1, 16, 32, 32]           2,304
      BatchNorm2d-22           [-1, 16, 32, 32]              32
             ReLU-23           [-1, 16, 32, 32]               0
         ResBlock-24           [-1, 16, 32, 32]               0
           Conv2d-25           [-1, 16, 32, 32]           2,304
      BatchNorm2d-26           [-1, 16, 32, 32]              32
             ReLU-27           [-1, 16, 32, 32]               0
           Conv2d-28           [-1, 16, 32, 32]           2,304
      BatchNorm2d-29           [-1, 16, 32, 32]              32
             ReLU-30           [-1, 16, 32, 32]               0
         ResBlock-31           [-1, 16, 32, 32]               0
           Conv2d-32           [-1, 16, 32, 32]           2,304
      BatchNorm2d-33           [-1, 16, 32, 32]              32
             ReLU-34           [-1, 16, 32, 32]               0
           Conv2d-35           [-1, 16, 32, 32]           2,304
      BatchNorm2d-36           [-1, 16, 32, 32]              32
             ReLU-37           [-1, 16, 32, 32]               0
         ResBlock-38           [-1, 16, 32, 32]               0
           Conv2d-39           [-1, 32, 16, 16]           4,608
      BatchNorm2d-40           [-1, 32, 16, 16]              64
             ReLU-41           [-1, 32, 16, 16]               0
           Conv2d-42           [-1, 32, 16, 16]           9,216
      BatchNorm2d-43           [-1, 32, 16, 16]              64
           Conv2d-44           [-1, 32, 16, 16]           4,608
      BatchNorm2d-45           [-1, 32, 16, 16]              64
             ReLU-46           [-1, 32, 16, 16]               0
         ResBlock-47           [-1, 32, 16, 16]               0
           Conv2d-48           [-1, 32, 16, 16]           9,216
      BatchNorm2d-49           [-1, 32, 16, 16]              64
             ReLU-50           [-1, 32, 16, 16]               0
           Conv2d-51           [-1, 32, 16, 16]           9,216
      BatchNorm2d-52           [-1, 32, 16, 16]              64
             ReLU-53           [-1, 32, 16, 16]               0
         ResBlock-54           [-1, 32, 16, 16]               0
           Conv2d-55           [-1, 32, 16, 16]           9,216
      BatchNorm2d-56           [-1, 32, 16, 16]              64
             ReLU-57           [-1, 32, 16, 16]               0
           Conv2d-58           [-1, 32, 16, 16]           9,216
      BatchNorm2d-59           [-1, 32, 16, 16]              64
             ReLU-60           [-1, 32, 16, 16]               0
         ResBlock-61           [-1, 32, 16, 16]               0
           Conv2d-62           [-1, 32, 16, 16]           9,216
      BatchNorm2d-63           [-1, 32, 16, 16]              64
             ReLU-64           [-1, 32, 16, 16]               0
           Conv2d-65           [-1, 32, 16, 16]           9,216
      BatchNorm2d-66           [-1, 32, 16, 16]              64
             ReLU-67           [-1, 32, 16, 16]               0
         ResBlock-68           [-1, 32, 16, 16]               0
           Conv2d-69           [-1, 32, 16, 16]           9,216
      BatchNorm2d-70           [-1, 32, 16, 16]              64
             ReLU-71           [-1, 32, 16, 16]               0
           Conv2d-72           [-1, 32, 16, 16]           9,216
      BatchNorm2d-73           [-1, 32, 16, 16]              64
             ReLU-74           [-1, 32, 16, 16]               0
         ResBlock-75           [-1, 32, 16, 16]               0
           Conv2d-76             [-1, 64, 8, 8]          18,432
      BatchNorm2d-77             [-1, 64, 8, 8]             128
             ReLU-78             [-1, 64, 8, 8]               0
           Conv2d-79             [-1, 64, 8, 8]          36,864
      BatchNorm2d-80             [-1, 64, 8, 8]             128
           Conv2d-81             [-1, 64, 8, 8]          18,432
      BatchNorm2d-82             [-1, 64, 8, 8]             128
             ReLU-83             [-1, 64, 8, 8]               0
         ResBlock-84             [-1, 64, 8, 8]               0
           Conv2d-85             [-1, 64, 8, 8]          36,864
      BatchNorm2d-86             [-1, 64, 8, 8]             128
             ReLU-87             [-1, 64, 8, 8]               0
           Conv2d-88             [-1, 64, 8, 8]          36,864
      BatchNorm2d-89             [-1, 64, 8, 8]             128
             ReLU-90             [-1, 64, 8, 8]               0
         ResBlock-91             [-1, 64, 8, 8]               0
           Conv2d-92             [-1, 64, 8, 8]          36,864
      BatchNorm2d-93             [-1, 64, 8, 8]             128
             ReLU-94             [-1, 64, 8, 8]               0
           Conv2d-95             [-1, 64, 8, 8]          36,864
      BatchNorm2d-96             [-1, 64, 8, 8]             128
             ReLU-97             [-1, 64, 8, 8]               0
         ResBlock-98             [-1, 64, 8, 8]               0
           Conv2d-99             [-1, 64, 8, 8]          36,864
     BatchNorm2d-100             [-1, 64, 8, 8]             128
            ReLU-101             [-1, 64, 8, 8]               0
          Conv2d-102             [-1, 64, 8, 8]          36,864
     BatchNorm2d-103             [-1, 64, 8, 8]             128
            ReLU-104             [-1, 64, 8, 8]               0
        ResBlock-105             [-1, 64, 8, 8]               0
          Conv2d-106             [-1, 64, 8, 8]          36,864
     BatchNorm2d-107             [-1, 64, 8, 8]             128
            ReLU-108             [-1, 64, 8, 8]               0
          Conv2d-109             [-1, 64, 8, 8]          36,864
     BatchNorm2d-110             [-1, 64, 8, 8]             128
            ReLU-111             [-1, 64, 8, 8]               0
        ResBlock-112             [-1, 64, 8, 8]               0
       AvgPool2d-113             [-1, 64, 1, 1]               0
          Linear-114                   [-1, 10]             650
          ResNet-115                   [-1, 10]               0
================================================================
Total params: 487,386
Trainable params: 487,386
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 8.22
Params size (MB): 1.86
Estimated Total Size (MB): 10.09
----------------------------------------------------------------

(tensor(487386), tensor(487386))
DATASET : CIFAR-10
MODEL : resnet32-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2c10ecfd0>
EPOCH 1 training begins...
Train epoch 1 / 50 Loss 2.1444, Accuracy 21.42% Training Time 0.29 min
saved model to ./pretrained/resnet32-cifar-50
Validation epoch 1 / 50 Loss 1.8726, Accuracy 29.03%

EPOCH 2 training begins...
Train epoch 2 / 50 Loss 1.8149, Accuracy 31.51% Training Time 0.29 min
Validation epoch 2 / 50 Loss 1.6641, Accuracy 37.79%

EPOCH 3 training begins...
Train epoch 3 / 50 Loss 1.6686, Accuracy 37.53% Training Time 0.29 min
Validation epoch 3 / 50 Loss 1.5883, Accuracy 41.04%

EPOCH 4 training begins...
Train epoch 4 / 50 Loss 1.5882, Accuracy 40.95% Training Time 0.29 min
Validation epoch 4 / 50 Loss 1.5116, Accuracy 43.57%

EPOCH 5 training begins...
Train epoch 5 / 50 Loss 1.5172, Accuracy 43.45% Training Time 0.29 min
Validation epoch 5 / 50 Loss 1.4633, Accuracy 46.97%

EPOCH 6 training begins...
Train epoch 6 / 50 Loss 1.4334, Accuracy 46.91% Training Time 0.29 min
Validation epoch 6 / 50 Loss 1.3416, Accuracy 50.26%

EPOCH 7 training begins...
Train epoch 7 / 50 Loss 1.3939, Accuracy 48.72% Training Time 0.29 min
Validation epoch 7 / 50 Loss 1.3168, Accuracy 52.12%

EPOCH 8 training begins...
Train epoch 8 / 50 Loss 1.3402, Accuracy 50.98% Training Time 0.29 min
Validation epoch 8 / 50 Loss 1.3263, Accuracy 50.86%

EPOCH 9 training begins...
Train epoch 9 / 50 Loss 1.2855, Accuracy 53.33% Training Time 0.29 min
Validation epoch 9 / 50 Loss 1.2138, Accuracy 56.24%

EPOCH 10 training begins...
Train epoch 10 / 50 Loss 1.2627, Accuracy 54.21% Training Time 0.29 min
Validation epoch 10 / 50 Loss 1.3372, Accuracy 52.41%

EPOCH 11 training begins...
Train epoch 11 / 50 Loss 1.1983, Accuracy 56.48% Training Time 0.29 min
Validation epoch 11 / 50 Loss 1.2235, Accuracy 56.52%

EPOCH 12 training begins...
Train epoch 12 / 50 Loss 1.1760, Accuracy 57.54% Training Time 0.29 min
Validation epoch 12 / 50 Loss 1.1178, Accuracy 59.11%

EPOCH 13 training begins...
Train epoch 13 / 50 Loss 1.1498, Accuracy 58.48% Training Time 0.29 min
Validation epoch 13 / 50 Loss 1.0812, Accuracy 61.17%

EPOCH 14 training begins...
Train epoch 14 / 50 Loss 1.1118, Accuracy 59.66% Training Time 0.29 min
Validation epoch 14 / 50 Loss 1.0424, Accuracy 62.60%

EPOCH 15 training begins...
Train epoch 15 / 50 Loss 1.0748, Accuracy 61.26% Training Time 0.29 min
Validation epoch 15 / 50 Loss 1.1048, Accuracy 59.96%

EPOCH 16 training begins...
Train epoch 16 / 50 Loss 1.0585, Accuracy 61.76% Training Time 0.29 min
Validation epoch 16 / 50 Loss 1.0233, Accuracy 63.51%

EPOCH 17 training begins...
Train epoch 17 / 50 Loss 1.0181, Accuracy 63.24% Training Time 0.29 min
Validation epoch 17 / 50 Loss 0.9882, Accuracy 64.97%

EPOCH 18 training begins...
Train epoch 18 / 50 Loss 0.9974, Accuracy 64.19% Training Time 0.29 min
Validation epoch 18 / 50 Loss 0.9912, Accuracy 64.77%

EPOCH 19 training begins...
Train epoch 19 / 50 Loss 0.9841, Accuracy 64.66% Training Time 0.29 min
Validation epoch 19 / 50 Loss 1.0295, Accuracy 63.93%

EPOCH 20 training begins...
Train epoch 20 / 50 Loss 0.9625, Accuracy 65.42% Training Time 0.29 min
Validation epoch 20 / 50 Loss 0.9564, Accuracy 65.72%

EPOCH 21 training begins...
Train epoch 21 / 50 Loss 0.9441, Accuracy 65.92% Training Time 0.29 min
Validation epoch 21 / 50 Loss 0.9286, Accuracy 66.88%

EPOCH 22 training begins...
Train epoch 22 / 50 Loss 0.9275, Accuracy 66.75% Training Time 0.29 min
Validation epoch 22 / 50 Loss 0.9491, Accuracy 66.06%

EPOCH 23 training begins...
Train epoch 23 / 50 Loss 0.9044, Accuracy 67.69% Training Time 0.29 min
Validation epoch 23 / 50 Loss 0.9190, Accuracy 67.88%

EPOCH 24 training begins...
Train epoch 24 / 50 Loss 0.8888, Accuracy 68.20% Training Time 0.29 min
Validation epoch 24 / 50 Loss 0.9319, Accuracy 67.34%

EPOCH 25 training begins...
Train epoch 25 / 50 Loss 0.8673, Accuracy 69.03% Training Time 0.29 min
Validation epoch 25 / 50 Loss 0.8722, Accuracy 68.94%

EPOCH 26 training begins...
Train epoch 26 / 50 Loss 0.8638, Accuracy 69.04% Training Time 0.29 min
Validation epoch 26 / 50 Loss 0.8968, Accuracy 68.61%

EPOCH 27 training begins...
Train epoch 27 / 50 Loss 0.8356, Accuracy 70.14% Training Time 0.29 min
Validation epoch 27 / 50 Loss 0.9018, Accuracy 68.53%

EPOCH 28 training begins...
Train epoch 28 / 50 Loss 0.8292, Accuracy 70.44% Training Time 0.29 min
Validation epoch 28 / 50 Loss 0.8708, Accuracy 69.25%

EPOCH 29 training begins...
Train epoch 29 / 50 Loss 0.8276, Accuracy 70.66% Training Time 0.29 min
Validation epoch 29 / 50 Loss 0.8602, Accuracy 69.50%

EPOCH 30 training begins...
Train epoch 30 / 50 Loss 0.8099, Accuracy 70.87% Training Time 0.29 min
Validation epoch 30 / 50 Loss 0.8637, Accuracy 69.48%

EPOCH 31 training begins...
Train epoch 31 / 50 Loss 0.7939, Accuracy 71.75% Training Time 0.29 min
Validation epoch 31 / 50 Loss 0.8716, Accuracy 69.55%

EPOCH 32 training begins...
Train epoch 32 / 50 Loss 0.7899, Accuracy 71.99% Training Time 0.29 min
Validation epoch 32 / 50 Loss 0.8043, Accuracy 71.88%

EPOCH 33 training begins...
Train epoch 33 / 50 Loss 0.7582, Accuracy 73.14% Training Time 0.29 min
Validation epoch 33 / 50 Loss 0.8141, Accuracy 71.94%

EPOCH 34 training begins...
Train epoch 34 / 50 Loss 0.7672, Accuracy 72.63% Training Time 0.29 min
Validation epoch 34 / 50 Loss 0.7960, Accuracy 72.33%

EPOCH 35 training begins...
Train epoch 35 / 50 Loss 0.7586, Accuracy 72.95% Training Time 0.29 min
Validation epoch 35 / 50 Loss 0.8092, Accuracy 71.85%

EPOCH 36 training begins...
Train epoch 36 / 50 Loss 0.7318, Accuracy 74.06% Training Time 0.29 min
Validation epoch 36 / 50 Loss 0.7914, Accuracy 73.12%

EPOCH 37 training begins...
Train epoch 37 / 50 Loss 0.7309, Accuracy 73.89% Training Time 0.29 min
Validation epoch 37 / 50 Loss 0.8741, Accuracy 70.98%

EPOCH 38 training begins...
Train epoch 38 / 50 Loss 0.7135, Accuracy 74.68% Training Time 0.29 min
Validation epoch 38 / 50 Loss 0.7822, Accuracy 72.97%

EPOCH 39 training begins...
Train epoch 39 / 50 Loss 0.7066, Accuracy 75.00% Training Time 0.29 min
Validation epoch 39 / 50 Loss 0.7557, Accuracy 73.51%

EPOCH 40 training begins...
Train epoch 40 / 50 Loss 0.6952, Accuracy 75.31% Training Time 0.29 min
Validation epoch 40 / 50 Loss 0.7339, Accuracy 74.59%

EPOCH 41 training begins...
Train epoch 41 / 50 Loss 0.7008, Accuracy 75.31% Training Time 0.29 min
Validation epoch 41 / 50 Loss 0.7447, Accuracy 73.70%

EPOCH 42 training begins...
Train epoch 42 / 50 Loss 0.6625, Accuracy 76.55% Training Time 0.29 min
Validation epoch 42 / 50 Loss 0.7614, Accuracy 73.37%

EPOCH 43 training begins...
Train epoch 43 / 50 Loss 0.6685, Accuracy 76.46% Training Time 0.29 min
Validation epoch 43 / 50 Loss 0.6938, Accuracy 75.89%

EPOCH 44 training begins...
Train epoch 44 / 50 Loss 0.6589, Accuracy 76.67% Training Time 0.29 min
Validation epoch 44 / 50 Loss 0.7474, Accuracy 75.28%

EPOCH 45 training begins...
Train epoch 45 / 50 Loss 0.6363, Accuracy 77.55% Training Time 0.29 min
Validation epoch 45 / 50 Loss 0.7043, Accuracy 75.55%

EPOCH 46 training begins...
Train epoch 46 / 50 Loss 0.6374, Accuracy 77.37% Training Time 0.29 min
Validation epoch 46 / 50 Loss 0.6985, Accuracy 75.90%

EPOCH 47 training begins...
Train epoch 47 / 50 Loss 0.6209, Accuracy 77.92% Training Time 0.29 min
Validation epoch 47 / 50 Loss 0.7533, Accuracy 74.50%

EPOCH 48 training begins...
Train epoch 48 / 50 Loss 0.5815, Accuracy 79.37% Training Time 0.29 min
Validation epoch 48 / 50 Loss 0.6535, Accuracy 77.23%

EPOCH 49 training begins...
Train epoch 49 / 50 Loss 0.5713, Accuracy 79.81% Training Time 0.29 min
Validation epoch 49 / 50 Loss 0.6451, Accuracy 78.36%

EPOCH 50 training begins...
Train epoch 50 / 50 Loss 0.5646, Accuracy 80.00% Training Time 0.29 min
Validation epoch 50 / 50 Loss 0.6571, Accuracy 77.61%

Total training time 16.13 minutes taken
DATASET : CIFAR-10
MODEL : resnet32-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.0005
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2c10ecfd0>
TESTSET AVG LOSS : 0.66
TESTSET AVG ACCR : 77.61%
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
            Conv2d-4           [-1, 16, 32, 32]           2,304
       BatchNorm2d-5           [-1, 16, 32, 32]              32
              ReLU-6           [-1, 16, 32, 32]               0
            Conv2d-7           [-1, 16, 32, 32]           2,304
       BatchNorm2d-8           [-1, 16, 32, 32]              32
              ReLU-9           [-1, 16, 32, 32]               0
         ResBlock-10           [-1, 16, 32, 32]               0
           Conv2d-11           [-1, 16, 32, 32]           2,304
      BatchNorm2d-12           [-1, 16, 32, 32]              32
             ReLU-13           [-1, 16, 32, 32]               0
           Conv2d-14           [-1, 16, 32, 32]           2,304
      BatchNorm2d-15           [-1, 16, 32, 32]              32
             ReLU-16           [-1, 16, 32, 32]               0
         ResBlock-17           [-1, 16, 32, 32]               0
           Conv2d-18           [-1, 16, 32, 32]           2,304
      BatchNorm2d-19           [-1, 16, 32, 32]              32
             ReLU-20           [-1, 16, 32, 32]               0
           Conv2d-21           [-1, 16, 32, 32]           2,304
      BatchNorm2d-22           [-1, 16, 32, 32]              32
             ReLU-23           [-1, 16, 32, 32]               0
         ResBlock-24           [-1, 16, 32, 32]               0
           Conv2d-25           [-1, 16, 32, 32]           2,304
      BatchNorm2d-26           [-1, 16, 32, 32]              32
             ReLU-27           [-1, 16, 32, 32]               0
           Conv2d-28           [-1, 16, 32, 32]           2,304
      BatchNorm2d-29           [-1, 16, 32, 32]              32
             ReLU-30           [-1, 16, 32, 32]               0
         ResBlock-31           [-1, 16, 32, 32]               0
           Conv2d-32           [-1, 16, 32, 32]           2,304
      BatchNorm2d-33           [-1, 16, 32, 32]              32
             ReLU-34           [-1, 16, 32, 32]               0
           Conv2d-35           [-1, 16, 32, 32]           2,304
      BatchNorm2d-36           [-1, 16, 32, 32]              32
             ReLU-37           [-1, 16, 32, 32]               0
         ResBlock-38           [-1, 16, 32, 32]               0
           Conv2d-39           [-1, 16, 32, 32]           2,304
      BatchNorm2d-40           [-1, 16, 32, 32]              32
             ReLU-41           [-1, 16, 32, 32]               0
           Conv2d-42           [-1, 16, 32, 32]           2,304
      BatchNorm2d-43           [-1, 16, 32, 32]              32
             ReLU-44           [-1, 16, 32, 32]               0
         ResBlock-45           [-1, 16, 32, 32]               0
           Conv2d-46           [-1, 16, 32, 32]           2,304
      BatchNorm2d-47           [-1, 16, 32, 32]              32
             ReLU-48           [-1, 16, 32, 32]               0
           Conv2d-49           [-1, 16, 32, 32]           2,304
      BatchNorm2d-50           [-1, 16, 32, 32]              32
             ReLU-51           [-1, 16, 32, 32]               0
         ResBlock-52           [-1, 16, 32, 32]               0
           Conv2d-53           [-1, 32, 16, 16]           4,608
      BatchNorm2d-54           [-1, 32, 16, 16]              64
             ReLU-55           [-1, 32, 16, 16]               0
           Conv2d-56           [-1, 32, 16, 16]           9,216
      BatchNorm2d-57           [-1, 32, 16, 16]              64
           Conv2d-58           [-1, 32, 16, 16]           4,608
      BatchNorm2d-59           [-1, 32, 16, 16]              64
             ReLU-60           [-1, 32, 16, 16]               0
         ResBlock-61           [-1, 32, 16, 16]               0
           Conv2d-62           [-1, 32, 16, 16]           9,216
      BatchNorm2d-63           [-1, 32, 16, 16]              64
             ReLU-64           [-1, 32, 16, 16]               0
           Conv2d-65           [-1, 32, 16, 16]           9,216
      BatchNorm2d-66           [-1, 32, 16, 16]              64
             ReLU-67           [-1, 32, 16, 16]               0
         ResBlock-68           [-1, 32, 16, 16]               0
           Conv2d-69           [-1, 32, 16, 16]           9,216
      BatchNorm2d-70           [-1, 32, 16, 16]              64
             ReLU-71           [-1, 32, 16, 16]               0
           Conv2d-72           [-1, 32, 16, 16]           9,216
      BatchNorm2d-73           [-1, 32, 16, 16]              64
             ReLU-74           [-1, 32, 16, 16]               0
         ResBlock-75           [-1, 32, 16, 16]               0
           Conv2d-76           [-1, 32, 16, 16]           9,216
      BatchNorm2d-77           [-1, 32, 16, 16]              64
             ReLU-78           [-1, 32, 16, 16]               0
           Conv2d-79           [-1, 32, 16, 16]           9,216
      BatchNorm2d-80           [-1, 32, 16, 16]              64
             ReLU-81           [-1, 32, 16, 16]               0
         ResBlock-82           [-1, 32, 16, 16]               0
           Conv2d-83           [-1, 32, 16, 16]           9,216
      BatchNorm2d-84           [-1, 32, 16, 16]              64
             ReLU-85           [-1, 32, 16, 16]               0
           Conv2d-86           [-1, 32, 16, 16]           9,216
      BatchNorm2d-87           [-1, 32, 16, 16]              64
             ReLU-88           [-1, 32, 16, 16]               0
         ResBlock-89           [-1, 32, 16, 16]               0
           Conv2d-90           [-1, 32, 16, 16]           9,216
      BatchNorm2d-91           [-1, 32, 16, 16]              64
             ReLU-92           [-1, 32, 16, 16]               0
           Conv2d-93           [-1, 32, 16, 16]           9,216
      BatchNorm2d-94           [-1, 32, 16, 16]              64
             ReLU-95           [-1, 32, 16, 16]               0
         ResBlock-96           [-1, 32, 16, 16]               0
           Conv2d-97           [-1, 32, 16, 16]           9,216
      BatchNorm2d-98           [-1, 32, 16, 16]              64
             ReLU-99           [-1, 32, 16, 16]               0
          Conv2d-100           [-1, 32, 16, 16]           9,216
     BatchNorm2d-101           [-1, 32, 16, 16]              64
            ReLU-102           [-1, 32, 16, 16]               0
        ResBlock-103           [-1, 32, 16, 16]               0
          Conv2d-104             [-1, 64, 8, 8]          18,432
     BatchNorm2d-105             [-1, 64, 8, 8]             128
            ReLU-106             [-1, 64, 8, 8]               0
          Conv2d-107             [-1, 64, 8, 8]          36,864
     BatchNorm2d-108             [-1, 64, 8, 8]             128
          Conv2d-109             [-1, 64, 8, 8]          18,432
     BatchNorm2d-110             [-1, 64, 8, 8]             128
            ReLU-111             [-1, 64, 8, 8]               0
        ResBlock-112             [-1, 64, 8, 8]               0
          Conv2d-113             [-1, 64, 8, 8]          36,864
     BatchNorm2d-114             [-1, 64, 8, 8]             128
            ReLU-115             [-1, 64, 8, 8]               0
          Conv2d-116             [-1, 64, 8, 8]          36,864
     BatchNorm2d-117             [-1, 64, 8, 8]             128
            ReLU-118             [-1, 64, 8, 8]               0
        ResBlock-119             [-1, 64, 8, 8]               0
          Conv2d-120             [-1, 64, 8, 8]          36,864
     BatchNorm2d-121             [-1, 64, 8, 8]             128
            ReLU-122             [-1, 64, 8, 8]               0
          Conv2d-123             [-1, 64, 8, 8]          36,864
     BatchNorm2d-124             [-1, 64, 8, 8]             128
            ReLU-125             [-1, 64, 8, 8]               0
        ResBlock-126             [-1, 64, 8, 8]               0
          Conv2d-127             [-1, 64, 8, 8]          36,864
     BatchNorm2d-128             [-1, 64, 8, 8]             128
            ReLU-129             [-1, 64, 8, 8]               0
          Conv2d-130             [-1, 64, 8, 8]          36,864
     BatchNorm2d-131             [-1, 64, 8, 8]             128
            ReLU-132             [-1, 64, 8, 8]               0
        ResBlock-133             [-1, 64, 8, 8]               0
          Conv2d-134             [-1, 64, 8, 8]          36,864
     BatchNorm2d-135             [-1, 64, 8, 8]             128
            ReLU-136             [-1, 64, 8, 8]               0
          Conv2d-137             [-1, 64, 8, 8]          36,864
     BatchNorm2d-138             [-1, 64, 8, 8]             128
            ReLU-139             [-1, 64, 8, 8]               0
        ResBlock-140             [-1, 64, 8, 8]               0
          Conv2d-141             [-1, 64, 8, 8]          36,864
     BatchNorm2d-142             [-1, 64, 8, 8]             128
            ReLU-143             [-1, 64, 8, 8]               0
          Conv2d-144             [-1, 64, 8, 8]          36,864
     BatchNorm2d-145             [-1, 64, 8, 8]             128
            ReLU-146             [-1, 64, 8, 8]               0
        ResBlock-147             [-1, 64, 8, 8]               0
          Conv2d-148             [-1, 64, 8, 8]          36,864
     BatchNorm2d-149             [-1, 64, 8, 8]             128
            ReLU-150             [-1, 64, 8, 8]               0
          Conv2d-151             [-1, 64, 8, 8]          36,864
     BatchNorm2d-152             [-1, 64, 8, 8]             128
            ReLU-153             [-1, 64, 8, 8]               0
        ResBlock-154             [-1, 64, 8, 8]               0
       AvgPool2d-155             [-1, 64, 1, 1]               0
          Linear-156                   [-1, 10]             650
          ResNet-157                   [-1, 10]               0
================================================================
Total params: 681,818
Trainable params: 681,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 11.28
Params size (MB): 2.60
Estimated Total Size (MB): 13.89
----------------------------------------------------------------

(tensor(681818), tensor(681818))
DATASET : CIFAR-10
MODEL : resnet44-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2a7ec9b80>
EPOCH 1 training begins...
Train epoch 1 / 50 Loss 2.1744, Accuracy 19.59% Training Time 0.39 min
saved model to ./pretrained/resnet44-cifar-50
Validation epoch 1 / 50 Loss 1.8663, Accuracy 29.68%

EPOCH 2 training begins...
Train epoch 2 / 50 Loss 1.7929, Accuracy 31.60% Training Time 0.39 min
Validation epoch 2 / 50 Loss 1.7186, Accuracy 36.23%

EPOCH 3 training begins...
Train epoch 3 / 50 Loss 1.6604, Accuracy 37.38% Training Time 0.39 min
Validation epoch 3 / 50 Loss 1.5578, Accuracy 41.26%

EPOCH 4 training begins...
Train epoch 4 / 50 Loss 1.5622, Accuracy 41.28% Training Time 0.39 min
Validation epoch 4 / 50 Loss 1.5014, Accuracy 44.18%

EPOCH 5 training begins...
Train epoch 5 / 50 Loss 1.5004, Accuracy 43.91% Training Time 0.39 min
Validation epoch 5 / 50 Loss 1.4391, Accuracy 46.34%

EPOCH 6 training begins...
Train epoch 6 / 50 Loss 1.4287, Accuracy 47.32% Training Time 0.39 min
Validation epoch 6 / 50 Loss 1.3370, Accuracy 50.68%

EPOCH 7 training begins...
Train epoch 7 / 50 Loss 1.3661, Accuracy 50.04% Training Time 0.39 min
Validation epoch 7 / 50 Loss 1.2943, Accuracy 52.54%

EPOCH 8 training begins...
Train epoch 8 / 50 Loss 1.3172, Accuracy 51.86% Training Time 0.39 min
Validation epoch 8 / 50 Loss 1.3433, Accuracy 51.04%

EPOCH 9 training begins...
Train epoch 9 / 50 Loss 1.2952, Accuracy 52.99% Training Time 0.39 min
Validation epoch 9 / 50 Loss 1.2549, Accuracy 54.81%

EPOCH 10 training begins...
Train epoch 10 / 50 Loss 1.2340, Accuracy 55.13% Training Time 0.39 min
Validation epoch 10 / 50 Loss 1.2316, Accuracy 55.75%

EPOCH 11 training begins...
Train epoch 11 / 50 Loss 1.2006, Accuracy 56.56% Training Time 0.39 min
Validation epoch 11 / 50 Loss 1.1475, Accuracy 58.66%

EPOCH 12 training begins...
Train epoch 12 / 50 Loss 1.1595, Accuracy 58.28% Training Time 0.39 min
Validation epoch 12 / 50 Loss 1.1235, Accuracy 59.24%

EPOCH 13 training begins...
Train epoch 13 / 50 Loss 1.1381, Accuracy 59.05% Training Time 0.39 min
Validation epoch 13 / 50 Loss 1.1118, Accuracy 60.40%

EPOCH 14 training begins...
Train epoch 14 / 50 Loss 1.1036, Accuracy 60.33% Training Time 0.39 min
Validation epoch 14 / 50 Loss 1.1044, Accuracy 60.82%

EPOCH 15 training begins...
Train epoch 15 / 50 Loss 1.0822, Accuracy 61.28% Training Time 0.39 min
Validation epoch 15 / 50 Loss 1.0522, Accuracy 62.91%

EPOCH 16 training begins...
Train epoch 16 / 50 Loss 1.0462, Accuracy 62.44% Training Time 0.39 min
Validation epoch 16 / 50 Loss 0.9931, Accuracy 64.65%

EPOCH 17 training begins...
Train epoch 17 / 50 Loss 1.0154, Accuracy 63.46% Training Time 0.39 min
Validation epoch 17 / 50 Loss 1.0526, Accuracy 62.51%

EPOCH 18 training begins...
Train epoch 18 / 50 Loss 1.0012, Accuracy 63.97% Training Time 0.39 min
Validation epoch 18 / 50 Loss 1.0364, Accuracy 63.03%

EPOCH 19 training begins...
Train epoch 19 / 50 Loss 0.9650, Accuracy 65.45% Training Time 0.39 min
Validation epoch 19 / 50 Loss 0.9776, Accuracy 65.83%

EPOCH 20 training begins...
Train epoch 20 / 50 Loss 0.9720, Accuracy 65.14% Training Time 0.39 min
Validation epoch 20 / 50 Loss 0.9323, Accuracy 67.14%

EPOCH 21 training begins...
Train epoch 21 / 50 Loss 0.9230, Accuracy 66.84% Training Time 0.39 min
Validation epoch 21 / 50 Loss 0.9264, Accuracy 66.92%

EPOCH 22 training begins...
Train epoch 22 / 50 Loss 0.9339, Accuracy 66.54% Training Time 0.39 min
Validation epoch 22 / 50 Loss 0.9318, Accuracy 66.99%

EPOCH 23 training begins...
Train epoch 23 / 50 Loss 0.9029, Accuracy 67.63% Training Time 0.39 min
Validation epoch 23 / 50 Loss 0.9300, Accuracy 67.34%

EPOCH 24 training begins...
Train epoch 24 / 50 Loss 0.8801, Accuracy 68.53% Training Time 0.39 min
Validation epoch 24 / 50 Loss 0.9075, Accuracy 67.89%

EPOCH 25 training begins...
Train epoch 25 / 50 Loss 0.8818, Accuracy 68.57% Training Time 0.39 min
Validation epoch 25 / 50 Loss 0.9046, Accuracy 68.40%

EPOCH 26 training begins...
Train epoch 26 / 50 Loss 0.8558, Accuracy 69.43% Training Time 0.39 min
Validation epoch 26 / 50 Loss 0.8493, Accuracy 70.20%

EPOCH 27 training begins...
Train epoch 27 / 50 Loss 0.8340, Accuracy 70.04% Training Time 0.39 min
Validation epoch 27 / 50 Loss 0.8812, Accuracy 69.24%

EPOCH 28 training begins...
Train epoch 28 / 50 Loss 0.8360, Accuracy 70.33% Training Time 0.39 min
Validation epoch 28 / 50 Loss 0.8517, Accuracy 70.47%

EPOCH 29 training begins...
Train epoch 29 / 50 Loss 0.8106, Accuracy 71.23% Training Time 0.39 min
Validation epoch 29 / 50 Loss 0.8704, Accuracy 69.11%

EPOCH 30 training begins...
Train epoch 30 / 50 Loss 0.7969, Accuracy 71.51% Training Time 0.39 min
Validation epoch 30 / 50 Loss 0.8965, Accuracy 69.01%

EPOCH 31 training begins...
Train epoch 31 / 50 Loss 0.7524, Accuracy 73.46% Training Time 0.39 min
Validation epoch 31 / 50 Loss 0.7856, Accuracy 72.49%

EPOCH 32 training begins...
Train epoch 32 / 50 Loss 0.7261, Accuracy 74.22% Training Time 0.39 min
Validation epoch 32 / 50 Loss 0.7784, Accuracy 72.89%

EPOCH 33 training begins...
Train epoch 33 / 50 Loss 0.7316, Accuracy 73.84% Training Time 0.39 min
Validation epoch 33 / 50 Loss 0.7612, Accuracy 73.31%

EPOCH 34 training begins...
Train epoch 34 / 50 Loss 0.7224, Accuracy 74.22% Training Time 0.39 min
Validation epoch 34 / 50 Loss 0.8078, Accuracy 72.45%

EPOCH 35 training begins...
Train epoch 35 / 50 Loss 0.7161, Accuracy 74.49% Training Time 0.39 min
Validation epoch 35 / 50 Loss 0.7870, Accuracy 72.77%

EPOCH 36 training begins...
Train epoch 36 / 50 Loss 0.7088, Accuracy 74.79% Training Time 0.39 min
Validation epoch 36 / 50 Loss 0.7561, Accuracy 73.88%

EPOCH 37 training begins...
Train epoch 37 / 50 Loss 0.6935, Accuracy 75.41% Training Time 0.39 min
Validation epoch 37 / 50 Loss 0.7888, Accuracy 72.93%

EPOCH 38 training begins...
Train epoch 38 / 50 Loss 0.7032, Accuracy 75.08% Training Time 0.39 min
Validation epoch 38 / 50 Loss 0.7715, Accuracy 73.28%

EPOCH 39 training begins...
Train epoch 39 / 50 Loss 0.6894, Accuracy 75.59% Training Time 0.39 min
Validation epoch 39 / 50 Loss 0.7459, Accuracy 74.39%

EPOCH 40 training begins...
Train epoch 40 / 50 Loss 0.6810, Accuracy 75.64% Training Time 0.39 min
Validation epoch 40 / 50 Loss 0.7349, Accuracy 74.49%

EPOCH 41 training begins...
Train epoch 41 / 50 Loss 0.6863, Accuracy 75.78% Training Time 0.39 min
Validation epoch 41 / 50 Loss 0.7431, Accuracy 74.63%

EPOCH 42 training begins...
Train epoch 42 / 50 Loss 0.6714, Accuracy 76.13% Training Time 0.39 min
Validation epoch 42 / 50 Loss 0.7370, Accuracy 74.69%

EPOCH 43 training begins...
Train epoch 43 / 50 Loss 0.6621, Accuracy 76.58% Training Time 0.39 min
Validation epoch 43 / 50 Loss 0.7281, Accuracy 74.79%

EPOCH 44 training begins...
Train epoch 44 / 50 Loss 0.6566, Accuracy 76.59% Training Time 0.39 min
Validation epoch 44 / 50 Loss 0.7149, Accuracy 75.69%

EPOCH 45 training begins...
Train epoch 45 / 50 Loss 0.6585, Accuracy 76.70% Training Time 0.39 min
Validation epoch 45 / 50 Loss 0.7292, Accuracy 74.86%

EPOCH 46 training begins...
Train epoch 46 / 50 Loss 0.6516, Accuracy 76.85% Training Time 0.39 min
Validation epoch 46 / 50 Loss 0.7154, Accuracy 75.54%

EPOCH 47 training begins...
Train epoch 47 / 50 Loss 0.6510, Accuracy 76.80% Training Time 0.39 min
Validation epoch 47 / 50 Loss 0.7063, Accuracy 75.65%

EPOCH 48 training begins...
Train epoch 48 / 50 Loss 0.6413, Accuracy 77.18% Training Time 0.39 min
Validation epoch 48 / 50 Loss 0.7311, Accuracy 74.97%

EPOCH 49 training begins...
Train epoch 49 / 50 Loss 0.6424, Accuracy 77.22% Training Time 0.39 min
Validation epoch 49 / 50 Loss 0.6986, Accuracy 76.45%

EPOCH 50 training begins...
Train epoch 50 / 50 Loss 0.6266, Accuracy 77.94% Training Time 0.39 min
Validation epoch 50 / 50 Loss 0.6975, Accuracy 75.91%

Total training time 21.55 minutes taken
DATASET : CIFAR-10
MODEL : resnet44-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.0005
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2a7ec9b80>
TESTSET AVG LOSS : 0.70
TESTSET AVG ACCR : 75.91%
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 32, 32]             432
       BatchNorm2d-2           [-1, 16, 32, 32]              32
              ReLU-3           [-1, 16, 32, 32]               0
            Conv2d-4           [-1, 16, 32, 32]           2,304
       BatchNorm2d-5           [-1, 16, 32, 32]              32
              ReLU-6           [-1, 16, 32, 32]               0
            Conv2d-7           [-1, 16, 32, 32]           2,304
       BatchNorm2d-8           [-1, 16, 32, 32]              32
              ReLU-9           [-1, 16, 32, 32]               0
         ResBlock-10           [-1, 16, 32, 32]               0
           Conv2d-11           [-1, 16, 32, 32]           2,304
      BatchNorm2d-12           [-1, 16, 32, 32]              32
             ReLU-13           [-1, 16, 32, 32]               0
           Conv2d-14           [-1, 16, 32, 32]           2,304
      BatchNorm2d-15           [-1, 16, 32, 32]              32
             ReLU-16           [-1, 16, 32, 32]               0
         ResBlock-17           [-1, 16, 32, 32]               0
           Conv2d-18           [-1, 16, 32, 32]           2,304
      BatchNorm2d-19           [-1, 16, 32, 32]              32
             ReLU-20           [-1, 16, 32, 32]               0
           Conv2d-21           [-1, 16, 32, 32]           2,304
      BatchNorm2d-22           [-1, 16, 32, 32]              32
             ReLU-23           [-1, 16, 32, 32]               0
         ResBlock-24           [-1, 16, 32, 32]               0
           Conv2d-25           [-1, 16, 32, 32]           2,304
      BatchNorm2d-26           [-1, 16, 32, 32]              32
             ReLU-27           [-1, 16, 32, 32]               0
           Conv2d-28           [-1, 16, 32, 32]           2,304
      BatchNorm2d-29           [-1, 16, 32, 32]              32
             ReLU-30           [-1, 16, 32, 32]               0
         ResBlock-31           [-1, 16, 32, 32]               0
           Conv2d-32           [-1, 16, 32, 32]           2,304
      BatchNorm2d-33           [-1, 16, 32, 32]              32
             ReLU-34           [-1, 16, 32, 32]               0
           Conv2d-35           [-1, 16, 32, 32]           2,304
      BatchNorm2d-36           [-1, 16, 32, 32]              32
             ReLU-37           [-1, 16, 32, 32]               0
         ResBlock-38           [-1, 16, 32, 32]               0
           Conv2d-39           [-1, 16, 32, 32]           2,304
      BatchNorm2d-40           [-1, 16, 32, 32]              32
             ReLU-41           [-1, 16, 32, 32]               0
           Conv2d-42           [-1, 16, 32, 32]           2,304
      BatchNorm2d-43           [-1, 16, 32, 32]              32
             ReLU-44           [-1, 16, 32, 32]               0
         ResBlock-45           [-1, 16, 32, 32]               0
           Conv2d-46           [-1, 16, 32, 32]           2,304
      BatchNorm2d-47           [-1, 16, 32, 32]              32
             ReLU-48           [-1, 16, 32, 32]               0
           Conv2d-49           [-1, 16, 32, 32]           2,304
      BatchNorm2d-50           [-1, 16, 32, 32]              32
             ReLU-51           [-1, 16, 32, 32]               0
         ResBlock-52           [-1, 16, 32, 32]               0
           Conv2d-53           [-1, 16, 32, 32]           2,304
      BatchNorm2d-54           [-1, 16, 32, 32]              32
             ReLU-55           [-1, 16, 32, 32]               0
           Conv2d-56           [-1, 16, 32, 32]           2,304
      BatchNorm2d-57           [-1, 16, 32, 32]              32
             ReLU-58           [-1, 16, 32, 32]               0
         ResBlock-59           [-1, 16, 32, 32]               0
           Conv2d-60           [-1, 16, 32, 32]           2,304
      BatchNorm2d-61           [-1, 16, 32, 32]              32
             ReLU-62           [-1, 16, 32, 32]               0
           Conv2d-63           [-1, 16, 32, 32]           2,304
      BatchNorm2d-64           [-1, 16, 32, 32]              32
             ReLU-65           [-1, 16, 32, 32]               0
         ResBlock-66           [-1, 16, 32, 32]               0
           Conv2d-67           [-1, 32, 16, 16]           4,608
      BatchNorm2d-68           [-1, 32, 16, 16]              64
             ReLU-69           [-1, 32, 16, 16]               0
           Conv2d-70           [-1, 32, 16, 16]           9,216
      BatchNorm2d-71           [-1, 32, 16, 16]              64
           Conv2d-72           [-1, 32, 16, 16]           4,608
      BatchNorm2d-73           [-1, 32, 16, 16]              64
             ReLU-74           [-1, 32, 16, 16]               0
         ResBlock-75           [-1, 32, 16, 16]               0
           Conv2d-76           [-1, 32, 16, 16]           9,216
      BatchNorm2d-77           [-1, 32, 16, 16]              64
             ReLU-78           [-1, 32, 16, 16]               0
           Conv2d-79           [-1, 32, 16, 16]           9,216
      BatchNorm2d-80           [-1, 32, 16, 16]              64
             ReLU-81           [-1, 32, 16, 16]               0
         ResBlock-82           [-1, 32, 16, 16]               0
           Conv2d-83           [-1, 32, 16, 16]           9,216
      BatchNorm2d-84           [-1, 32, 16, 16]              64
             ReLU-85           [-1, 32, 16, 16]               0
           Conv2d-86           [-1, 32, 16, 16]           9,216
      BatchNorm2d-87           [-1, 32, 16, 16]              64
             ReLU-88           [-1, 32, 16, 16]               0
         ResBlock-89           [-1, 32, 16, 16]               0
           Conv2d-90           [-1, 32, 16, 16]           9,216
      BatchNorm2d-91           [-1, 32, 16, 16]              64
             ReLU-92           [-1, 32, 16, 16]               0
           Conv2d-93           [-1, 32, 16, 16]           9,216
      BatchNorm2d-94           [-1, 32, 16, 16]              64
             ReLU-95           [-1, 32, 16, 16]               0
         ResBlock-96           [-1, 32, 16, 16]               0
           Conv2d-97           [-1, 32, 16, 16]           9,216
      BatchNorm2d-98           [-1, 32, 16, 16]              64
             ReLU-99           [-1, 32, 16, 16]               0
          Conv2d-100           [-1, 32, 16, 16]           9,216
     BatchNorm2d-101           [-1, 32, 16, 16]              64
            ReLU-102           [-1, 32, 16, 16]               0
        ResBlock-103           [-1, 32, 16, 16]               0
          Conv2d-104           [-1, 32, 16, 16]           9,216
     BatchNorm2d-105           [-1, 32, 16, 16]              64
            ReLU-106           [-1, 32, 16, 16]               0
          Conv2d-107           [-1, 32, 16, 16]           9,216
     BatchNorm2d-108           [-1, 32, 16, 16]              64
            ReLU-109           [-1, 32, 16, 16]               0
        ResBlock-110           [-1, 32, 16, 16]               0
          Conv2d-111           [-1, 32, 16, 16]           9,216
     BatchNorm2d-112           [-1, 32, 16, 16]              64
            ReLU-113           [-1, 32, 16, 16]               0
          Conv2d-114           [-1, 32, 16, 16]           9,216
     BatchNorm2d-115           [-1, 32, 16, 16]              64
            ReLU-116           [-1, 32, 16, 16]               0
        ResBlock-117           [-1, 32, 16, 16]               0
          Conv2d-118           [-1, 32, 16, 16]           9,216
     BatchNorm2d-119           [-1, 32, 16, 16]              64
            ReLU-120           [-1, 32, 16, 16]               0
          Conv2d-121           [-1, 32, 16, 16]           9,216
     BatchNorm2d-122           [-1, 32, 16, 16]              64
            ReLU-123           [-1, 32, 16, 16]               0
        ResBlock-124           [-1, 32, 16, 16]               0
          Conv2d-125           [-1, 32, 16, 16]           9,216
     BatchNorm2d-126           [-1, 32, 16, 16]              64
            ReLU-127           [-1, 32, 16, 16]               0
          Conv2d-128           [-1, 32, 16, 16]           9,216
     BatchNorm2d-129           [-1, 32, 16, 16]              64
            ReLU-130           [-1, 32, 16, 16]               0
        ResBlock-131           [-1, 32, 16, 16]               0
          Conv2d-132             [-1, 64, 8, 8]          18,432
     BatchNorm2d-133             [-1, 64, 8, 8]             128
            ReLU-134             [-1, 64, 8, 8]               0
          Conv2d-135             [-1, 64, 8, 8]          36,864
     BatchNorm2d-136             [-1, 64, 8, 8]             128
          Conv2d-137             [-1, 64, 8, 8]          18,432
     BatchNorm2d-138             [-1, 64, 8, 8]             128
            ReLU-139             [-1, 64, 8, 8]               0
        ResBlock-140             [-1, 64, 8, 8]               0
          Conv2d-141             [-1, 64, 8, 8]          36,864
     BatchNorm2d-142             [-1, 64, 8, 8]             128
            ReLU-143             [-1, 64, 8, 8]               0
          Conv2d-144             [-1, 64, 8, 8]          36,864
     BatchNorm2d-145             [-1, 64, 8, 8]             128
            ReLU-146             [-1, 64, 8, 8]               0
        ResBlock-147             [-1, 64, 8, 8]               0
          Conv2d-148             [-1, 64, 8, 8]          36,864
     BatchNorm2d-149             [-1, 64, 8, 8]             128
            ReLU-150             [-1, 64, 8, 8]               0
          Conv2d-151             [-1, 64, 8, 8]          36,864
     BatchNorm2d-152             [-1, 64, 8, 8]             128
            ReLU-153             [-1, 64, 8, 8]               0
        ResBlock-154             [-1, 64, 8, 8]               0
          Conv2d-155             [-1, 64, 8, 8]          36,864
     BatchNorm2d-156             [-1, 64, 8, 8]             128
            ReLU-157             [-1, 64, 8, 8]               0
          Conv2d-158             [-1, 64, 8, 8]          36,864
     BatchNorm2d-159             [-1, 64, 8, 8]             128
            ReLU-160             [-1, 64, 8, 8]               0
        ResBlock-161             [-1, 64, 8, 8]               0
          Conv2d-162             [-1, 64, 8, 8]          36,864
     BatchNorm2d-163             [-1, 64, 8, 8]             128
            ReLU-164             [-1, 64, 8, 8]               0
          Conv2d-165             [-1, 64, 8, 8]          36,864
     BatchNorm2d-166             [-1, 64, 8, 8]             128
            ReLU-167             [-1, 64, 8, 8]               0
        ResBlock-168             [-1, 64, 8, 8]               0
          Conv2d-169             [-1, 64, 8, 8]          36,864
     BatchNorm2d-170             [-1, 64, 8, 8]             128
            ReLU-171             [-1, 64, 8, 8]               0
          Conv2d-172             [-1, 64, 8, 8]          36,864
     BatchNorm2d-173             [-1, 64, 8, 8]             128
            ReLU-174             [-1, 64, 8, 8]               0
        ResBlock-175             [-1, 64, 8, 8]               0
          Conv2d-176             [-1, 64, 8, 8]          36,864
     BatchNorm2d-177             [-1, 64, 8, 8]             128
            ReLU-178             [-1, 64, 8, 8]               0
          Conv2d-179             [-1, 64, 8, 8]          36,864
     BatchNorm2d-180             [-1, 64, 8, 8]             128
            ReLU-181             [-1, 64, 8, 8]               0
        ResBlock-182             [-1, 64, 8, 8]               0
          Conv2d-183             [-1, 64, 8, 8]          36,864
     BatchNorm2d-184             [-1, 64, 8, 8]             128
            ReLU-185             [-1, 64, 8, 8]               0
          Conv2d-186             [-1, 64, 8, 8]          36,864
     BatchNorm2d-187             [-1, 64, 8, 8]             128
            ReLU-188             [-1, 64, 8, 8]               0
        ResBlock-189             [-1, 64, 8, 8]               0
          Conv2d-190             [-1, 64, 8, 8]          36,864
     BatchNorm2d-191             [-1, 64, 8, 8]             128
            ReLU-192             [-1, 64, 8, 8]               0
          Conv2d-193             [-1, 64, 8, 8]          36,864
     BatchNorm2d-194             [-1, 64, 8, 8]             128
            ReLU-195             [-1, 64, 8, 8]               0
        ResBlock-196             [-1, 64, 8, 8]               0
       AvgPool2d-197             [-1, 64, 1, 1]               0
          Linear-198                   [-1, 10]             650
          ResNet-199                   [-1, 10]               0
================================================================
Total params: 876,250
Trainable params: 876,250
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 14.34
Params size (MB): 3.34
Estimated Total Size (MB): 17.70
----------------------------------------------------------------

(tensor(876250), tensor(876250))
DATASET : CIFAR-10
MODEL : resnet56-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2a7d8e820>
EPOCH 1 training begins...
Train epoch 1 / 50 Loss 2.1701, Accuracy 19.33% Training Time 0.51 min
saved model to ./pretrained/resnet56-cifar-50
Validation epoch 1 / 50 Loss 1.9012, Accuracy 29.13%

EPOCH 2 training begins...
Train epoch 2 / 50 Loss 1.8626, Accuracy 29.55% Training Time 0.50 min
Validation epoch 2 / 50 Loss 1.7113, Accuracy 34.90%

EPOCH 3 training begins...
Train epoch 3 / 50 Loss 1.7368, Accuracy 34.60% Training Time 0.50 min
Validation epoch 3 / 50 Loss 1.6403, Accuracy 38.95%

EPOCH 4 training begins...
Train epoch 4 / 50 Loss 1.6495, Accuracy 38.49% Training Time 0.50 min
Validation epoch 4 / 50 Loss 1.5711, Accuracy 41.44%

EPOCH 5 training begins...
Train epoch 5 / 50 Loss 1.5719, Accuracy 41.73% Training Time 0.50 min
Validation epoch 5 / 50 Loss 1.4870, Accuracy 44.54%

EPOCH 6 training begins...
Train epoch 6 / 50 Loss 1.5031, Accuracy 44.57% Training Time 0.50 min
Validation epoch 6 / 50 Loss 1.4557, Accuracy 45.82%

EPOCH 7 training begins...
Train epoch 7 / 50 Loss 1.4622, Accuracy 46.23% Training Time 0.50 min
Validation epoch 7 / 50 Loss 1.4542, Accuracy 46.07%

EPOCH 8 training begins...
Train epoch 8 / 50 Loss 1.4482, Accuracy 47.02% Training Time 0.50 min
Validation epoch 8 / 50 Loss 1.3708, Accuracy 49.06%

EPOCH 9 training begins...
Train epoch 9 / 50 Loss 1.3930, Accuracy 49.10% Training Time 0.50 min
Validation epoch 9 / 50 Loss 1.3273, Accuracy 51.37%

EPOCH 10 training begins...
Train epoch 10 / 50 Loss 1.3386, Accuracy 51.10% Training Time 0.50 min
Validation epoch 10 / 50 Loss 1.3180, Accuracy 51.91%

EPOCH 11 training begins...
Train epoch 11 / 50 Loss 1.3057, Accuracy 52.06% Training Time 0.50 min
Validation epoch 11 / 50 Loss 1.2553, Accuracy 53.72%

EPOCH 12 training begins...
Train epoch 12 / 50 Loss 1.2560, Accuracy 54.16% Training Time 0.50 min
Validation epoch 12 / 50 Loss 1.1650, Accuracy 57.72%

EPOCH 13 training begins...
Train epoch 13 / 50 Loss 1.2156, Accuracy 56.06% Training Time 0.50 min
Validation epoch 13 / 50 Loss 1.1375, Accuracy 58.29%

EPOCH 14 training begins...
Train epoch 14 / 50 Loss 1.1765, Accuracy 57.55% Training Time 0.50 min
Validation epoch 14 / 50 Loss 1.1516, Accuracy 58.43%

EPOCH 15 training begins...
Train epoch 15 / 50 Loss 1.1597, Accuracy 57.96% Training Time 0.50 min
Validation epoch 15 / 50 Loss 1.1476, Accuracy 58.79%

EPOCH 16 training begins...
Train epoch 16 / 50 Loss 1.1196, Accuracy 59.54% Training Time 0.50 min
Validation epoch 16 / 50 Loss 1.0601, Accuracy 62.00%

EPOCH 17 training begins...
Train epoch 17 / 50 Loss 1.1154, Accuracy 59.91% Training Time 0.50 min
Validation epoch 17 / 50 Loss 1.1491, Accuracy 58.83%

EPOCH 18 training begins...
Train epoch 18 / 50 Loss 1.0813, Accuracy 61.34% Training Time 0.50 min
Validation epoch 18 / 50 Loss 1.0582, Accuracy 62.21%

EPOCH 19 training begins...
Train epoch 19 / 50 Loss 1.0236, Accuracy 63.16% Training Time 0.50 min
Validation epoch 19 / 50 Loss 1.0261, Accuracy 63.37%

EPOCH 20 training begins...
Train epoch 20 / 50 Loss 1.0154, Accuracy 63.36% Training Time 0.50 min
Validation epoch 20 / 50 Loss 1.0389, Accuracy 63.69%

EPOCH 21 training begins...
Train epoch 21 / 50 Loss 0.9801, Accuracy 64.58% Training Time 0.50 min
Validation epoch 21 / 50 Loss 0.9582, Accuracy 65.77%

EPOCH 22 training begins...
Train epoch 22 / 50 Loss 0.9709, Accuracy 65.28% Training Time 0.50 min
Validation epoch 22 / 50 Loss 0.9349, Accuracy 66.69%

EPOCH 23 training begins...
Train epoch 23 / 50 Loss 0.9579, Accuracy 65.62% Training Time 0.50 min
Validation epoch 23 / 50 Loss 0.9310, Accuracy 67.22%

EPOCH 24 training begins...
Train epoch 24 / 50 Loss 0.9316, Accuracy 66.72% Training Time 0.50 min
Validation epoch 24 / 50 Loss 0.9102, Accuracy 68.14%

EPOCH 25 training begins...
Train epoch 25 / 50 Loss 0.9171, Accuracy 67.14% Training Time 0.50 min
Validation epoch 25 / 50 Loss 0.9469, Accuracy 66.56%

EPOCH 26 training begins...
Train epoch 26 / 50 Loss 0.8973, Accuracy 68.03% Training Time 0.50 min
Validation epoch 26 / 50 Loss 0.9043, Accuracy 68.16%

EPOCH 27 training begins...
Train epoch 27 / 50 Loss 0.8798, Accuracy 68.66% Training Time 0.50 min
Validation epoch 27 / 50 Loss 0.9199, Accuracy 68.01%

EPOCH 28 training begins...
Train epoch 28 / 50 Loss 0.8629, Accuracy 69.22% Training Time 0.50 min
Validation epoch 28 / 50 Loss 0.8835, Accuracy 68.88%

EPOCH 29 training begins...
Train epoch 29 / 50 Loss 0.8348, Accuracy 70.45% Training Time 0.50 min
Validation epoch 29 / 50 Loss 0.8441, Accuracy 70.07%

EPOCH 30 training begins...
Train epoch 30 / 50 Loss 0.8497, Accuracy 69.79% Training Time 0.50 min
Validation epoch 30 / 50 Loss 0.8492, Accuracy 70.49%

EPOCH 31 training begins...
Train epoch 31 / 50 Loss 0.8209, Accuracy 70.63% Training Time 0.50 min
Validation epoch 31 / 50 Loss 0.8260, Accuracy 70.62%

EPOCH 32 training begins...
Train epoch 32 / 50 Loss 0.8004, Accuracy 71.35% Training Time 0.50 min
Validation epoch 32 / 50 Loss 0.8146, Accuracy 72.16%

EPOCH 33 training begins...
Train epoch 33 / 50 Loss 0.7868, Accuracy 72.07% Training Time 0.50 min
Validation epoch 33 / 50 Loss 0.8078, Accuracy 71.44%

EPOCH 34 training begins...
Train epoch 34 / 50 Loss 0.7924, Accuracy 72.06% Training Time 0.50 min
Validation epoch 34 / 50 Loss 0.7738, Accuracy 72.82%

EPOCH 35 training begins...
Train epoch 35 / 50 Loss 0.7752, Accuracy 72.38% Training Time 0.50 min
Validation epoch 35 / 50 Loss 0.7728, Accuracy 73.27%

EPOCH 36 training begins...
Train epoch 36 / 50 Loss 0.7503, Accuracy 73.29% Training Time 0.50 min
Validation epoch 36 / 50 Loss 0.8171, Accuracy 71.82%

EPOCH 37 training begins...
Train epoch 37 / 50 Loss 0.7498, Accuracy 73.44% Training Time 0.50 min
Validation epoch 37 / 50 Loss 0.7507, Accuracy 74.01%

EPOCH 38 training begins...
Train epoch 38 / 50 Loss 0.7459, Accuracy 73.49% Training Time 0.50 min
Validation epoch 38 / 50 Loss 0.8028, Accuracy 71.90%

EPOCH 39 training begins...
Train epoch 39 / 50 Loss 0.7225, Accuracy 74.40% Training Time 0.50 min
Validation epoch 39 / 50 Loss 0.7215, Accuracy 75.00%

EPOCH 40 training begins...
Train epoch 40 / 50 Loss 0.7016, Accuracy 75.17% Training Time 0.50 min
Validation epoch 40 / 50 Loss 0.7554, Accuracy 74.43%

EPOCH 41 training begins...
Train epoch 41 / 50 Loss 0.6926, Accuracy 75.49% Training Time 0.50 min
Validation epoch 41 / 50 Loss 0.7565, Accuracy 74.73%

EPOCH 42 training begins...
Train epoch 42 / 50 Loss 0.6885, Accuracy 75.54% Training Time 0.50 min
Validation epoch 42 / 50 Loss 0.7474, Accuracy 74.97%

EPOCH 43 training begins...
Train epoch 43 / 50 Loss 0.6809, Accuracy 75.84% Training Time 0.51 min
Validation epoch 43 / 50 Loss 0.7195, Accuracy 74.76%

EPOCH 44 training begins...
Train epoch 44 / 50 Loss 0.6667, Accuracy 76.62% Training Time 0.50 min
Validation epoch 44 / 50 Loss 0.6845, Accuracy 76.50%

EPOCH 45 training begins...
Train epoch 45 / 50 Loss 0.6639, Accuracy 76.68% Training Time 0.50 min
Validation epoch 45 / 50 Loss 0.7316, Accuracy 75.63%

EPOCH 46 training begins...
Train epoch 46 / 50 Loss 0.6579, Accuracy 76.89% Training Time 0.50 min
Validation epoch 46 / 50 Loss 0.7056, Accuracy 75.86%

EPOCH 47 training begins...
Train epoch 47 / 50 Loss 0.6430, Accuracy 77.30% Training Time 0.50 min
Validation epoch 47 / 50 Loss 0.6945, Accuracy 76.16%

EPOCH 48 training begins...
Train epoch 48 / 50 Loss 0.6415, Accuracy 77.19% Training Time 0.50 min
Validation epoch 48 / 50 Loss 0.6979, Accuracy 76.46%

EPOCH 49 training begins...
Train epoch 49 / 50 Loss 0.5814, Accuracy 79.59% Training Time 0.50 min
Validation epoch 49 / 50 Loss 0.6470, Accuracy 78.03%

EPOCH 50 training begins...
Train epoch 50 / 50 Loss 0.5749, Accuracy 79.70% Training Time 0.50 min
Validation epoch 50 / 50 Loss 0.6886, Accuracy 76.62%

Total training time 27.22 minutes taken
DATASET : CIFAR-10
MODEL : resnet56-cifar-50
OPTIMIZER : SGD (
Parameter Group 0
    dampening: 0
    lr: 0.0005
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
SCHEDULER : <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fd2a7d8e820>
TESTSET AVG LOSS : 0.69
TESTSET AVG ACCR : 76.62%